{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import OrderedDict\n",
    "\n",
    "import ROOT\n",
    "ROOT.gROOT.SetBatch(True)\n",
    "from ROOT import TCanvas, TFile, TProfile, TNtuple, TH1F, TH2F, TH1D, TH2D, THStack, TF1\n",
    "from ROOT import gBenchmark, gRandom, gSystem, Double, gPad, TFitResultPtr, TMath\n",
    "import root_numpy\n",
    "import psutil\n",
    "import pandas\n",
    "import math\n",
    "#matplotlib.use('agg')\n",
    "%matplotlib inline\n",
    "import matplotlib #as matplot\n",
    "print(matplotlib.__version__)\n",
    "#print(matplotlib.path)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pylab\n",
    "import sklearn as sk\n",
    "print(sk.__version__)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "######################\n",
    "import keras as kr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Input\n",
    "from keras.layers import Reshape, MaxPooling2D\n",
    "from keras.layers import Conv2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU, PReLU \n",
    "from keras.optimizers import Adamax\n",
    "from keras.optimizers import Nadam\n",
    "print(kr.__version__)\n",
    "#from keras import backend as K\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=32, \\\n",
    "                        inter_op_parallelism_threads=32, \\\n",
    "                        allow_soft_placement=True, \\\n",
    "                        device_count = {'CPU': 32}\n",
    "                       )\n",
    "session = tf.Session(config=config)\n",
    "#K.set_session(session)\n",
    "## it will issue a warning, just ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test that matplotlib imported ok\n",
    "x1, y1 = [-1, 12], [1, 4]\n",
    "x2, y2 = [1, 10], [3, 2]\n",
    "plt.plot(x1, y1, x2, y2, marker = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel='2l_2tau_HH'\n",
    "\n",
    "startTime = datetime.now()\n",
    "execfile(\"../python/data_manager.py\") \n",
    "\n",
    "if channel=='2l_2tau_HH' : \n",
    "    execfile(\"../cards/info_2l_2tau_HH.py\") \n",
    "    execfile(\"../cards/auxiliary_functions_2l_2tau_HH.py\") ## Loading the functions and setup variables specific to 2l_2tau channels \n",
    "    execfile(\"../cards/NN_settings_2l_2tau_HH.py\") ## Loading the boolean settings specific to 2l_2tau channel\n",
    "    \n",
    "log_file_name=channel+\".log\"\n",
    "if 'evtLevelSUM_HH_2l_2tau_res' in bdtType:\n",
    "    file1_ = open(log_file_name, 'w+')\n",
    "else: \n",
    "    file1_ = open('roc.log','w+')    \n",
    "\n",
    "\n",
    "import shutil,subprocess\n",
    "proc=subprocess.Popen(['mkdir '+channel],shell=True,stdout=subprocess.PIPE)\n",
    "out = proc.stdout.read()    \n",
    "    \n",
    "    \n",
    "output = read_from(Bkg_mass_rand, tauID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"read from:\", output[\"inputPath\"])\n",
    "print (\"Date: \", time.asctime( time.localtime(time.time()) ))\n",
    "\n",
    "if(TrainMode == 0): ## All Masses included in training \n",
    "    data=load_data_2017(\n",
    "            output[\"inputPath\"],\n",
    "            output[\"channelInTree\"],\n",
    "            trainVars(True),\n",
    "            [],\n",
    "            bdtType,\n",
    "            channel,\n",
    "            output[\"keys\"],\n",
    "            output[\"masses\"],\n",
    "            output[\"mass_randomization\"],\n",
    "            )\n",
    "    mass_list = output[\"masses\"]\n",
    "    test_masses = output[\"masses_test\"]\n",
    "elif(TrainMode == 1): ## Only Low Masses (<= 400 GeV) included in training                                                                                                                                                                                              \n",
    "        data=load_data_2017(\n",
    "            output[\"inputPath\"],\n",
    "            output[\"channelInTree\"],\n",
    "            trainVars(True),\n",
    "            [],\n",
    "            bdtType,\n",
    "            channel,\n",
    "            output[\"keys\"],\n",
    "            output[\"masses_low\"],\n",
    "            output[\"mass_randomization\"],\n",
    "            )\n",
    "        mass_list = output[\"masses_low\"]\n",
    "        test_masses = output[\"masses_test_low\"]\n",
    "elif(TrainMode == 2): ## Only High Masses (> 400 GeV) included in training                                                                                                                                                                                              \n",
    "        data=load_data_2017(\n",
    "            output[\"inputPath\"],\n",
    "            output[\"channelInTree\"],\n",
    "            trainVars(True),\n",
    "            [],\n",
    "            bdtType,\n",
    "            channel,\n",
    "            output[\"keys\"],\n",
    "            output[\"masses_high\"],\n",
    "            output[\"mass_randomization\"],\n",
    "            )\n",
    "        mass_list = output[\"masses_high\"]\n",
    "        test_masses = output[\"masses_test_high\"]\n",
    "else:        \n",
    "    data=load_data_2017(\n",
    "        output[\"inputPath\"], \n",
    "        output[\"channelInTree\"], \n",
    "        trainVars(True), \n",
    "        [], \n",
    "        bdtType, \n",
    "        channel,\n",
    "        output[\"keys\"], \n",
    "        output[\"masses\"],\n",
    "        output[\"mass_randomization\"]\n",
    "        ) # note: I had to add channel as argument of the function\n",
    "    mass_list = output[\"masses\"]\n",
    "    test_masses = output[\"masses_test\"]\n",
    "    \n",
    "    \n",
    "#data.dropna(subset=[\"totalWeight\"],inplace = True) ## Was used in the BDT code\n",
    "#data.fillna(0)                                     ## Was used in the BDT code\n",
    "\n",
    "print (len(data))\n",
    "print (\"Date: \", time.asctime( time.localtime(time.time()) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAll=False\n",
    "BDTvariables=trainVars(plotAll, variables, bdtType)\n",
    "\n",
    "import copy\n",
    "\n",
    "## Removing gen_mHH from the list of input variables                                                                                                                                                                                                                    \n",
    "BDTvariables_wo_gen_mHH = copy.deepcopy(BDTvariables)  ## Works                                                                                                                                                                                                         \n",
    "BDTvariables_wo_gen_mHH.remove(\"gen_mHH\")\n",
    "\n",
    "trainvar = variables\n",
    "\n",
    "if channel=='2l_2tau_HH' :\n",
    "    labelBKG = \"TT+DY+VV\"\n",
    "else:\n",
    "    labelBKG = \"TT+DY+VV+W\"\n",
    "    \n",
    "print(\"mass_list\", mass_list)\n",
    "print(\"test_masses\", test_masses)\n",
    "\n",
    "if((channel=='2l_2tau_HH') and do_ReweightVars):\n",
    "        DoFits = True\n",
    "        print DoFits\n",
    "        print(\"Perfoming Fits to TProfile plots for signal\")\n",
    "        ## --- Making TProfile plots with fits (Signal) --- ###\n",
    "        MakeTProfile_New(channel, data, BDTvariables_wo_gen_mHH, 1, DoFits, \"before\", TrainMode, mass_list)\n",
    "else:\n",
    "        DoFits = False\n",
    "        print DoFits\n",
    "        print(\"Not Perfoming Fits to TProfile plots for signal\")\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "if((channel=='2l_2tau_HH') and do_2l_2tau_diagnostics == True):  \n",
    "    ## --- Making TProfile plots w/o fits (background) --- ###                                                                                                                                           \n",
    "    MakeTProfile_New(channel, data, BDTvariables_wo_gen_mHH, 0, False, \"before\", TrainMode, mass_list)        \n",
    "\n",
    "    ## --- Making 1D Histo plots (background) --- ###                                                                                                                                                                                                                   \n",
    "    MakeHisto1D_New(channel, data, BDTvariables, \"before\")\n",
    "\n",
    "    ## --- Making 1D THStack plots (background) --- ###                                                                                                                                                                                                                 \n",
    "    MakeTHStack_New(channel, data, BDTvariables, \"before\")\n",
    "else:\n",
    "    print(\"No plots will be made for 2l_2tau diagnostics\")  \n",
    "\n",
    "if((channel=='2l_2tau_HH') and do_ReweightVars):\n",
    "    ## ----- SCALING I/P VAR.S IN DATA USING THE FITS DONE ABOVE---- ###                                                                                                                                                                                            \n",
    "    ReweightDataframe_New(data, channel, BDTvariables_wo_gen_mHH, mass_list)\n",
    "else:\n",
    "    print(\"No plots and fits will be made for 2l_2tau diagnostics\")\n",
    "    \n",
    "    \n",
    "weights=\"evtWeight\"\n",
    "\n",
    "print (\"Date: \", time.asctime( time.localtime(time.time()) ))\n",
    "data[\"weight_cx\"] = data[weights]\n",
    "data[\"weight_train\"] = data[weights]\n",
    "data[\"NN_output\"] = 1.0\n",
    "\n",
    "print (\"separate datasets odd/even\")\n",
    "data_even = data.loc[(data[\"event\"].values % 2 == 0) ]\n",
    "data_odd = data.loc[~(data[\"event\"].values % 2 == 0) ]\n",
    "\n",
    "order_train = [data_odd, data_even]\n",
    "order_train_name = [\"odd\",\"even\"]\n",
    "\n",
    "\n",
    "print (\"balance datasets by even/odd chunck\")\n",
    "for data_do in order_train :\n",
    "    #### Normalization by cross section                                                                                                                                                                                                                                   \n",
    "    for wei in [\"weight_cx\", \"weight_train\"] :\n",
    "        if 'SUM_HH' in bdtType :\n",
    "            data_do.loc[(data_do['key'].isin(['TTTo2L2Nu','TTToSemiLeptonic'])), [wei]]              *= output[\"TTdatacard\"]/data_do.loc[(data_do['key'].isin(['TTTo2L2Nu','TTToSemiLeptonic'])), weights].sum()\n",
    "            data_do.loc[(data_do['key']=='DY'), [wei]]                            *= output[\"DYdatacard\"]/data_do.loc[(data_do['key']=='DY'), weights].sum()\n",
    "            if \"evtLevelSUM_HH_bb1l_res\" in bdtType :\n",
    "                data_do.loc[(data_do['key']=='W'), [wei]]                         *= Wdatacard/data_do.loc[(data_do['key']=='W')].sum() ## Saswati check please !!!                                                                                                       \n",
    "        if \"evtLevelSUM_HH_2l_2tau_res\" in bdtType :\n",
    "               #data_do.loc[(data_do['key']=='TTZJets'), [wei]]                       *= output[\"TTZdatacard\"]/data_do.loc[(data_do['key']=='TTZJets'), weights].sum() ## TTZJets                                                                                          \n",
    "               #data_do.loc[(data_do['key']=='TTWJets'), [wei]]                       *= output[\"TTWdatacard\"]/data_do.loc[(data_do['key']=='TTWJets'), weights].sum() ## TTWJets + TTWW                                                                                   \n",
    "               data_do.loc[(data_do['key']=='ZZ'), [wei]]                            *= output[\"ZZdatacard\"]/data_do.loc[(data_do['key']=='ZZ'), weights].sum() ## ZZ +ZZZ                                                                                                \n",
    "               data_do.loc[(data_do['key']=='WZ'), [wei]]                            *= output[\"WZdatacard\"]/data_do.loc[(data_do['key']=='WZ'), weights].sum() ## WZ + WZZ_4F                                                                                            \n",
    "               data_do.loc[(data_do['key']=='WW'), [wei]]                            *= output[\"WWdatacard\"]/data_do.loc[(data_do['key']=='WW'), weights].sum() ## WW + WWZ + WWW_4F                                                                                      \n",
    "               #data_do.loc[(data_do['key']=='VH'), [wei]]                        *= output[\"VHdatacard\"]/data_do.loc[(data_do['key']=='VH'), weights].sum() # consider removing                                                                                          \n",
    "               #data_do.loc[(data_do['key']=='TTH'), [wei]]                       *= output[\"TTHdatacard\"]/data_do.loc[(data_do['key']=='TTH'), weights].sum() # consider removing    \n",
    "    ### Normalize sig/BKG and do table of nevents/mass\n",
    "    for mass in output[\"masses\"] :\n",
    "        data_do.loc[(data_do['target']==1) & (data_do[\"gen_mHH\"] == mass),\"weight_train\"] *= 10000./data_do.loc[(data_do['target']==1) & (data_do[\"gen_mHH\"]== mass), \"weight_train\"].sum() ## Changed from 1000\n",
    "        data_do.loc[(data_do['target']==0) & (data_do[\"gen_mHH\"] == mass),\"weight_train\"] *= 10000./data_do.loc[(data_do['target']==0) & (data_do[\"gen_mHH\"]== mass), \"weight_train\"].sum() ## Changed from 1000 \n",
    "    print (\"Date: \", time.asctime( time.localtime(time.time()) ))\n",
    "\n",
    "    print (\"training statistics by mass\")\n",
    "    for mass in output[\"masses\"] :\n",
    "        print (\n",
    "               str(mass)+\": sig = \"+\\\n",
    "               str(len(data_do.loc[(data['target']==1) & (data_do[\"gen_mHH\"] == mass),[\"weight_train\"]]))+\\\n",
    "               \" BKG = \"+str(len(data_do.loc[(data['target']==0) & (data_do[\"gen_mHH\"] == mass),[\"weight_train\"]]))\n",
    "              )\n",
    "\n",
    "    print (\"\\n norm by mass - test\")\n",
    "    for mass in output[\"masses\"] :\n",
    "        print (\n",
    "               str(mass)+\": sig = \"+\\\n",
    "               str(data_do.loc[(data_do['target']==1) & (data_do[\"gen_mHH\"] == mass),\"weight_train\"].sum())+\\\n",
    "               \" BKG = \"+str(data_do.loc[(data_do['target']==0) & (data_do[\"gen_mHH\"] == mass),\"weight_train\"].sum())\n",
    "              )\n",
    "\n",
    "if((channel=='2l_2tau_HH') and do_2l_2tau_diagnostics == True):        \n",
    "    ## ----Merging the odd and even data-sets ---------------------------------------####                                                                                                                                                                               \n",
    "    ## ---(reweighting the merged dataframe by 0.5 as it is derived from 2 halves) ---###                                                                                                                                                                               \n",
    "    data_odd_copy = data_odd.copy(deep=True) ## Making sure we do not alter the halves used for roc curves later                                                                                                                                                        \n",
    "    data_even_copy = data_even.copy(deep=True) ## Making sure we do not alter the halves used for roc curves later                                                                                                                                                      \n",
    "    data_do = data_odd_copy.append(data_even_copy, ignore_index=True)\n",
    "    data_do.loc[data_do['target']==0, [weights]] *= 0.5\n",
    "    data_do.loc[data_do['target']==1, [weights]] *= 0.5\n",
    "    label = \"after\"\n",
    "\n",
    "    ## --- Making TProfile plots w/o fitting (Signal) --- ###                                                                                                                                                                                                           \n",
    "    MakeTProfile_New(channel, data, BDTvariables_wo_gen_mHH, 1, False, label, TrainMode, mass_list)\n",
    "\n",
    "    ## --- Making TProfile plots (background) --- ###                                                                                                                                                                                                                   \n",
    "    MakeTProfile_New(channel, data, BDTvariables_wo_gen_mHH, 0, False, label, TrainMode, mass_list)\n",
    "\n",
    "    ## --- Making 1D Histo plots (background) --- ###                                                                                                                                                                                                                   \n",
    "    MakeHisto1D_New(channel, data,  BDTvariables, label)\n",
    "\n",
    "    ## --- Making 1D THStack plots (background) --- ###                                                                                                                                                                                                                 \n",
    "    MakeTHStack_New(channel, data, BDTvariables, label)\n",
    "else:\n",
    "    print(\"No plots will be made for 2l_2tau diagnostics\")    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check of the resulting weights - the sizes of the training weight\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "if(channel=='2l_2tau_HH'):\n",
    "    keysToBKG = ['WW', 'WZ', 'ZZ', 'DY', 'TTTo2L2Nu', 'TTToSemiLeptonic'] # 'VH', 'TTH', 'TTToHadronic', 'TTZJets', 'TTWJets' \n",
    "else:\n",
    "    keysToBKG = ['WW', 'WZ', 'ZZ', 'DY', 'TTTo2L2Nu', 'TTToSemiLeptonic', 'W']\n",
    "    \n",
    "#colors = ['cyan','orange','k','r','green','magenta','b',]\n",
    "vars = [\"weight_train\"]#\"multitarget\"]\n",
    "\n",
    "for kk, key in enumerate(keysToBKG) :\n",
    "  for vv, var in enumerate(vars) : \n",
    "    ax.hist(\n",
    "        np.array(data.loc[(data['key']==key), var].values,dtype='float64'), # \n",
    "        weights=data.loc[(data['key']==key), \"evtWeight\"], # \"weight_train_cat\"\n",
    "        range=(-1.0,10.),bins=40, histtype='step', normed=True, lw=2, \n",
    "        label=key\n",
    "    )\n",
    "    ax.set_xlabel(var)\n",
    "ax.legend(loc=\"best\", title= channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the variables\n",
    "#trainvar = trainVars(False, \"testVars2\")\n",
    "#print trainvar\n",
    "trainvar = trainVars(False, variables, bdtType) ## = BDTvariables\n",
    "print trainvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Draw some plots on lists of variables for BKG\n",
    "\"\"\"\n",
    "#keysToBKG = ['TTZJets', 'WZ', 'ZZ', 'DY', 'VH', 'ttH', 'TTTo2L2Nu']\n",
    " \n",
    "## i try to do 3 X 3 plots (= enter up to nine entries in each sublist)\n",
    "## try to add strictly decreasing variables as first in each sublist, better for the legend positioning\n",
    "#listdraw = [\n",
    "#    [ 'tau1_pt', 'tau2_pt', 'mT_lep1', 'mT_lep2', 'met', 'm_ll', 'mTauTau', 'diHiggsVisMass', 'diHiggsMass' ], \n",
    "#    ['nBJet_medium', 'nElectron', 'max_tau_eta', 'max_lep_eta', 'gen_mHH'],\n",
    "#]\n",
    "\n",
    "if(channel=='2l_2tau_HH'):\n",
    "    listdraw = [\n",
    "        ['diHiggsMass', 'diHiggsVisMass', 'tau1_pt', 'nBJet_medium', 'nElectron', 'dr_lep_tau_min_SS', 'met_LD', 'tau2_pt', 'dr_lep_tau_min_OS'],\n",
    "        ['gen_mHH'],\n",
    "               ]\n",
    "else:\n",
    "    listdraw = [\n",
    "        ['diHiggsMass', 'diHiggsVisMass', 'tau1_pt', 'nBJet_medium', 'nElectron', 'dr_lep_tau_min_SS', 'met_LD', 'tau2_pt', 'dr_lep_tau_min_OS'],\n",
    "        ['gen_mHH'],\n",
    "               ]\n",
    "\n",
    "for featuresDraw in listdraw:\n",
    "    sizeArray=int(math.sqrt(len(featuresDraw))) if math.sqrt(len(featuresDraw)) % int(math.sqrt(len(featuresDraw))) == 0 else int(math.sqrt(len(featuresDraw)))+1\n",
    "    plt.figure(figsize=(4*sizeArray,4*sizeArray))\n",
    "    for n, feature in enumerate(featuresDraw) :\n",
    "        min_value, max_value = np.percentile(data[feature], [0.0, 99])\n",
    "        # fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        plt.subplot(sizeArray, sizeArray, n+1)\n",
    "        for kk, key in enumerate(keysToBKG) :\n",
    "            if 'TTZJets' in key or 'TTWJets' in key : linestyle = \"--\"\n",
    "            else :linestyle = \"-\"\n",
    "            plt.hist(\n",
    "            np.array(data.loc[(data['key']==key), feature].values,dtype='float64'), \n",
    "            weights=data.loc[(data['key']==key) , \"evtWeight\"], \n",
    "            range=(min_value, max_value), \n",
    "            bins=12, histtype='step', ls=linestyle, \n",
    "            normed=True, lw=2, #color=colors[kk],\n",
    "            label=key\n",
    "            )\n",
    "            plt.xlabel(feature)\n",
    "        if n == 0 : plt.legend(loc=\"upper right\", title= channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for featuresDraw in listdraw:\n",
    "    sizeArray=int(math.sqrt(len(featuresDraw))) if math.sqrt(len(featuresDraw)) % int(math.sqrt(len(featuresDraw))) == 0 else int(math.sqrt(len(featuresDraw)))+1\n",
    "    plt.figure(figsize=(4*sizeArray,4*sizeArray))\n",
    "    for n, feature in enumerate(featuresDraw) :\n",
    "        min_value, max_value = np.percentile(data[feature], [0.0, 99])\n",
    "        # fig, ax = plt.subplots(figsize=(4, 4))\n",
    "        plt.subplot(sizeArray, sizeArray, n+1)\n",
    "        for mass in [300,400,700] :\n",
    "            plt.hist(\n",
    "            np.array(data.loc[(data[\"gen_mHH\"] == mass), feature].values,dtype='float64'), \n",
    "            weights=data.loc[(data[\"gen_mHH\"] == mass) , \"evtWeight\"], \n",
    "            range=(min_value, max_value), \n",
    "            bins=10, histtype='step', ls=linestyle, \n",
    "            normed=True, lw=2, #color=colors[kk],\n",
    "            label=\"mass = \"+str(mass)\n",
    "            )\n",
    "        plt.hist(\n",
    "        np.array(data.loc[(data['target']==0), feature].values,dtype='float64'), \n",
    "        weights=data.loc[(data['target']==0) , \"evtWeight\"], \n",
    "        range=(min_value, max_value), \n",
    "        bins=10, histtype='step', ls='--', \n",
    "        normed=True, lw=3, color='k',\n",
    "        label=\"BKG\"\n",
    "        )\n",
    "        plt.xlabel(feature)\n",
    "        if n == 0 : plt.legend(loc=\"upper right\", title= channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model -- for binary activation='sigmoid'\n",
    "nclasses = 1\n",
    "\n",
    "## ---- Set these values for NN hyper-parameters (for gen_mHH as Input Var.) --- ##                                                                                                                                                                                                                     \n",
    "EPOCHS=100 # 50 is more optimum\n",
    "DROPOUT=0.05 # 0.01 is more optimum\n",
    "LR=0.00005\n",
    "SCHEDULE_DECAY=0.000005\n",
    "BATCH_SIZE=256 \n",
    "#EPOCHS=35\n",
    "#DROPOUT=0.01\n",
    "#LR=0.0005\n",
    "#SCHEDULE_DECAY=0.00005\n",
    "#BATCH_SIZE=256 ## 32,256\n",
    "##----------------------------------------------------------##       \n",
    "\n",
    "## ---- Set these values for NN hyper-parameters (w/o gen_mHH as Input Var.) --- ##                                                                                                                                                                                                                     \n",
    "EPOCHS2=35\n",
    "DROPOUT2=0.01\n",
    "LR2=0.0005\n",
    "SCHEDULE_DECAY2=0.00005\n",
    "BATCH_SIZE2=256 ## 32,256\n",
    "##----------------------------------------------------------##       \n",
    "\n",
    "\n",
    "hyppar=str(variables)+\"_epochs_\"+str(EPOCHS)+\"_dropout_\"+num_to_str(DROPOUT)+\"_lr_\"+num_to_str(LR)+\"_sch_decay_\"+num_to_str(SCHEDULE_DECAY)+\"_batch_size_\"+str(BATCH_SIZE)\n",
    "hyppar2=str(variables)+\"_wo_gen_mHH\"+\"_epochs_\"+str(EPOCHS2)+\"_dropout_\"+num_to_str(DROPOUT2)+\"_lr_\"+num_to_str(LR2)+\"_sch_decay_\"+num_to_str(SCHEDULE_DECAY2)+\"_batch_size_\"+str(BATCH_SIZE2)\n",
    "\n",
    "print hyppar\n",
    "print(\"DROPOUT\", DROPOUT)\n",
    "print(\"LR\", LR)\n",
    "print(\"SCHEDULE_DECAY\", SCHEDULE_DECAY)\n",
    "\n",
    "print hyppar2\n",
    "print(\"DROPOUT2\", DROPOUT2)\n",
    "print(\"LR2\", LR2)\n",
    "print(\"SCHEDULE_DECAY2\", SCHEDULE_DECAY2)\n",
    "\n",
    "\n",
    "features = trainvar # = BDTvariables\n",
    "features2 = BDTvariables_wo_gen_mHH\n",
    "\n",
    "def nn_model_binary():\n",
    "    \"create a model.\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2*len(features), input_dim=len(features), kernel_initializer='he_uniform')) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(DROPOUT)) #0.1\n",
    "    for Nnodes in [8,8] :\n",
    "        model.add(Dense(Nnodes, kernel_initializer='he_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(PReLU())\n",
    "        model.add(Dropout(DROPOUT)) #0.1\n",
    "    model.add(Dense(nclasses, activation='sigmoid'))\n",
    "    model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=Nadam(lr=LR, schedule_decay=SCHEDULE_DECAY), ##  lr=0.0005, sch_dec.=0.00005   # , beta_1 = 0.95, beta_2 = 0.999\n",
    "    metrics=['accuracy'], \n",
    "    )\n",
    "    return model\n",
    "\n",
    "def nn_model_binary_wo_gen_mHH():\n",
    "    \"create a model.\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2*len(features2), input_dim=len(features2), kernel_initializer='he_uniform')) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(DROPOUT2)) #0.1\n",
    "    for Nnodes in [8,8] :\n",
    "        model.add(Dense(Nnodes, kernel_initializer='he_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(PReLU())\n",
    "        model.add(Dropout(DROPOUT2)) #0.1\n",
    "    model.add(Dense(nclasses, activation='sigmoid'))\n",
    "    model.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=Nadam(lr=LR2, schedule_decay=SCHEDULE_DECAY2), ##  lr=0.0005, sch_dec.=0.00005   # , beta_1 = 0.95, beta_2 = 0.999\n",
    "    metrics=['accuracy'], \n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_binary().summary()\n",
    "nn_model_binary_wo_gen_mHH().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Port Keras Framework into SK-Learn\n",
    "# https://stackoverflow.com/questions/39467496/error-when-using-keras-sk-learn-api\n",
    "k_model_binary  = KerasClassifier(\n",
    "    build_fn=nn_model_binary, ## For gen_mHH as input Var.\n",
    "    epochs=EPOCHS,            ## For gen_mHH as input Var.\n",
    "    batch_size=BATCH_SIZE,    ## For gen_mHH as input Var.\n",
    "    verbose=2                 ## For gen_mHH as input Var.\n",
    "    #build_fn=nn_model_binary_wo_gen_mHH, ## w/o gen_mHH as input Var.\n",
    "    #epochs=EPOCHS2,                      ## w/o gen_mHH as input Var. \n",
    "    #batch_size=BATCH_SIZE2,              ## w/o gen_mHH as input Var.\n",
    "    #verbose=2                            ## w/o gen_mHH as input Var.\n",
    ")\n",
    "\n",
    "k_model_binary2  = KerasClassifier(\n",
    "    build_fn=nn_model_binary, ## For gen_mHH as input Var.\n",
    "    epochs=EPOCHS,            ## For gen_mHH as input Var. \n",
    "    batch_size=BATCH_SIZE,    ## For gen_mHH as input Var.\n",
    "    verbose=2                 ## For gen_mHH as input Var.\n",
    "    #build_fn=nn_model_binary_wo_gen_mHH, ## w/o gen_mHH as input Var.\n",
    "    #epochs=EPOCHS2,                      ## w/o gen_mHH as input Var. \n",
    "    #batch_size=BATCH_SIZE2,              ## w/o gen_mHH as input Var.\n",
    "    #verbose=2                            ## w/o gen_mHH as input Var.\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "print(\"data_odd[features].values\", data_odd[features].values)\n",
    "print(\"data_odd[target].values\", data_odd['target'].values)\n",
    "print(\"sample_weight=data_odd[weight_train].values\", data_odd[\"weight_train\"].values)\n",
    "\n",
    "history = k_model_binary.fit(\n",
    "    data_odd[features].values, ## For gen_mHH as input Var.\n",
    "    #data_odd[features2].values, ## w/o gen_mHH as input Var.\n",
    "    data_odd['target'].values,\n",
    "    sample_weight=data_odd[\"weight_train\"].values,\n",
    "    validation_data=(\n",
    "        data_even[features].values, ## For gen_mHH as input Var.\n",
    "        #data_even[features2].values, ## w/o gen_mHH as input Var.\n",
    "        data_even['target'].values, \n",
    "        data_even[\"weight_train\"].values\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "history2 = k_model_binary2.fit(\n",
    "    data_even[features].values, ## For gen_mHH as input Var.\n",
    "    #data_even[features2].values, ## w/o gen_mHH as input Var.\n",
    "    data_even['target'].values,\n",
    "    sample_weight=data_even[\"weight_train\"].values,\n",
    "    validation_data=(\n",
    "        data_odd[features].values, ## For gen_mHH as input Var.\n",
    "        #data_odd[features2].values,  ## w/o gen_mHH as input Var. \n",
    "        data_odd['target'].values, \n",
    "        data_odd[\"weight_train\"].values\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "overtraining test\n",
    "\"\"\"\n",
    "# Extract number of run epochs from the training history\n",
    "epochs = range(1, len(history.history[\"loss\"])+1)\n",
    "plt.figure(figsize=(9, 4))\n",
    "#fig = plt.figure(figsize=(4, 4))\n",
    "#plt.subplot(1, 2, 1)\n",
    "plt.subplot(2, 2, 1)\n",
    "# Extract loss on training and validation dataset and plot them together\n",
    "plt.plot(epochs, history.history[\"loss\"], \"o-\", label=\"Training (Odd)\")\n",
    "plt.plot(epochs, history.history[\"val_loss\"], \"o-\", label=\"Validation (Even)\")\n",
    "plt.xlabel(\"Epochs\"), plt.ylabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "#plt.xlim(0,40)\n",
    "plt.ylim(0.2,0.8)\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\");\n",
    "\n",
    "#plt.subplot(1, 2, 2)\n",
    "plt.subplot(2, 2, 2)\n",
    "#fig = plt.figure(figsize=(4, 4))\n",
    "# Extract loss on training and validation dataset and plot them together\n",
    "plt.plot(epochs, history.history[\"acc\"], \"o-\", label=\"Training (Odd)\")\n",
    "plt.plot(epochs, history.history[\"val_acc\"], \"o-\", label=\"Validation (Even)\")\n",
    "plt.xlabel(\"Epochs\"), plt.ylabel(\"Accuracy\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(0.4,0.9)\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "# Extract loss on training and validation dataset and plot them together\n",
    "plt.plot(epochs, history2.history[\"loss\"], \"o-\", label=\"Training (Even)\")\n",
    "plt.plot(epochs, history2.history[\"val_loss\"], \"o-\", label=\"Validation (Odd)\")\n",
    "plt.xlabel(\"Epochs\"), plt.ylabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "#plt.xlim(0,40)\n",
    "plt.ylim(0.2,0.8)\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\");\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "#fig = plt.figure(figsize=(4, 4))\n",
    "# Extract loss on training and validation dataset and plot them together\n",
    "plt.plot(epochs, history2.history[\"acc\"], \"o-\", label=\"Training (Even)\")\n",
    "plt.plot(epochs, history2.history[\"val_acc\"], \"o-\", label=\"Validation (Odd)\")\n",
    "plt.xlabel(\"Epochs\"), plt.ylabel(\"Accuracy\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(0.4,0.9)\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "filename1=\"{}/loss_and_acc_{}_Log.pdf\".format(channel, hyppar) ## For gen_mHH as input Var.\n",
    "#filename1=\"{}/loss_and_acc_{}_Log.pdf\".format(channel, hyppar2) ## w/o gen_mHH as input Var.\n",
    "plt.savefig(filename1);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ram/.local/lib/python2.7/site-packages')\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\"\"\"\n",
    "to calculate variables importance, it takes time and it is not completelly 'enlightant',\n",
    "do not do all the time.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Date: \", time.asctime( time.localtime(time.time()) ))\n",
    "perm = PermutationImportance(k_model_binary, random_state=1).fit( # , scoring=\"f1_samples\"\n",
    "    data_odd[features].values, ## For gen_mHH as input Var.\n",
    "    #data_odd[features2].values, ## w/o gen_mHH as input Var.\n",
    "    data_odd['target'].values,\n",
    "    sample_weight=data_odd[\"weight_train\"].values\n",
    ")\n",
    "print (\"Date: \", time.asctime( time.localtime(time.time()) ))\n",
    "eli5.show_weights(perm, feature_names = data_odd[features].columns.tolist(), top=len(features)) ## For gen_mHH as input Var.\n",
    "#eli5.show_weights(perm, feature_names = data_odd[features2].columns.tolist(), top=len(features2)) ## w/o gen_mHH as input Var.\n",
    "\n",
    "print (\"Date: \", time.asctime( time.localtime(time.time()) ))\n",
    "perm2 = PermutationImportance(k_model_binary2, random_state=1).fit( # , scoring=\"f1_samples\"\n",
    "    data_even[features].values, ## For gen_mHH as input Var.\n",
    "    #data_even[features2].values, ## w/o gen_mHH as input Var.\n",
    "    data_even['target'].values,\n",
    "    sample_weight=data_even[\"weight_train\"].values\n",
    ")\n",
    "print (\"Date: \", time.asctime( time.localtime(time.time()) ))\n",
    "eli5.show_weights(perm2, feature_names = data_even[features].columns.tolist(), top=len(features)) ## For gen_mHH as input Var.\n",
    "#eli5.show_weights(perm2, feature_names = data_even[features2].columns.tolist(), top=len(features2)) ## w/o gen_mHH as input Var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the output in all dataset \n",
    "-- to pass to the training/test\n",
    "\"\"\"\n",
    "\n",
    "## For gen_mHH as input Var.\n",
    "data_odd[\"NN_output\"]  = k_model_binary.predict_proba(data_odd[features].values, verbose=1)[:, 1]\n",
    "data_even[\"NN_output\"] = k_model_binary2.predict_proba(data_even[features].values, verbose=1)[:, 1]\n",
    "\n",
    "## w/o gen_mHH as input Var.\n",
    "#data_odd[\"NN_output\"]  = k_model_binary.predict_proba(data_odd[features2].values, verbose=1)[:, 1]\n",
    "#data_even[\"NN_output\"] = k_model_binary2.predict_proba(data_even[features2].values, verbose=1)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_params = {'normed': True, 'bins': 10 , 'histtype':'step'}\n",
    "target = 'target'\n",
    "plt.clf()\n",
    "\n",
    "plt.figure('XGB',figsize=(6, 6))\n",
    "\n",
    "values, bins, _ = plt.hist(\n",
    "    data_odd.loc[data_odd.target.values == 1, \"NN_output\"].values , \n",
    "    weights=data_odd.loc[data_odd.target.values == 1, \"weight_cx\"].values,\n",
    "    label=\"sig odd\", color='r', range=(0,1), **hist_params\n",
    "    )\n",
    "values, bins, _ = plt.hist(\n",
    "    data_odd.loc[data_odd.target.values == 0, \"NN_output\"].values , \n",
    "    weights=data_odd.loc[data_odd.target.values == 0, \"weight_cx\"].values,\n",
    "    label=\"BKG odd\", color='g', range=(0,1), **hist_params\n",
    "    )\n",
    "\n",
    "values, bins, _ = plt.hist(\n",
    "    data_even.loc[data_even.target.values == 1, \"NN_output\"].values , \n",
    "    weights=(data_even.loc[data_even.target.values == 1, \"weight_cx\"].values),\n",
    "    label=\"sig even\", color='r', ls='--', range=(0,1), **hist_params)\n",
    "values, bins, _ = plt.hist(\n",
    "    data_even.loc[data_even.target.values == 0, \"NN_output\"].values , \n",
    "    weights=(data_even.loc[data_even.target.values == 0, \"weight_cx\"].values),\n",
    "    label=\"BKG even\", color='g', ls='--', range=(0,1), **hist_params)\n",
    "\n",
    "#plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc='upper center')\n",
    "#filename2=\"{}/NN_Output_{}.pdf\".format(channel, hyppar) ## For gen_mHH as input Var.\n",
    "filename2=\"{}/NN_Output_{}.pdf\".format(channel, hyppar2) ## w/o gen_mHH as input Var.\n",
    "plt.savefig(filename2);\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# ROC Curve\n",
    "styleline = ['-', '--', '-.', ':']\n",
    "colors_mass = ['m', 'b', 'k', 'r', 'g',  'y', 'c', ]\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sl = 0\n",
    "\n",
    "for dd, data_do in  enumerate(order_train) :\n",
    "        if dd == 0 : val_data = 1\n",
    "        else : val_data = 0\n",
    "        #print data_do[\"weight_cx\"].astype(np.float64)  \n",
    "        #print data_do.NN_output.values\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "                data_do[\"target\"].astype(np.bool), \n",
    "                data_do.NN_output.values, \n",
    "                sample_weight=data_do[\"weight_cx\"].astype(np.float64)\n",
    "        )\n",
    "        train_auc = auc(fpr, tpr, reorder = True)\n",
    "        print(\"train set auc \" + str(train_auc))\n",
    "        fprt, tprt, thresholds = roc_curve(\n",
    "            order_train[val_data][\"target\"].astype(np.bool), \n",
    "            order_train[val_data].NN_output.values, \n",
    "            sample_weight=(order_train[val_data][\"weight_cx\"].astype(np.float64))\n",
    "        )\n",
    "        test_auct = auc(fprt, tprt, reorder = True)\n",
    "        print(\"test set auc \" + str(test_auct))\n",
    "        ax.plot(\n",
    "            fpr, tpr,\n",
    "            lw = 2, linestyle = styleline[dd + dd*1], color = colors_mass[1],\n",
    "            label = order_train_name[dd] + ' train (area = %0.3f)'%(train_auc) + \")\"\n",
    "            )\n",
    "        sl += 1\n",
    "        ax.plot(\n",
    "            fprt, tprt,\n",
    "            lw = 2, linestyle = styleline[dd + 1 + + dd*1], color = colors_mass[2],\n",
    "            label = order_train_name[dd] + ' test (area = %0.3f)'%(test_auct) + \")\"\n",
    "            )\n",
    "        sl += 1\n",
    "ax.set_ylim([0.0,1.0])\n",
    "ax.set_xlim([0.0,1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend(loc=\"lower right\", fontsize = 'small')\n",
    "ax.grid()\n",
    "\n",
    "#filename2a=\"{}/ROC_{}.pdf\".format(channel, hyppar) ## For gen_mHH as input Var.\n",
    "filename2a=\"{}/ROC_{}.pdf\".format(channel, hyppar2) ## w/o gen_mHH as input Var.\n",
    "plt.savefig(filename2a);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "## classifier plot by mass\n",
    "hist_params = {'normed': True, 'bins': 8 , 'histtype':'step', \"lw\": 2}\n",
    "plt.clf()\n",
    "colorcold = ['g', 'r', 'y']\n",
    "colorhot = ['b', 'magenta', 'orange']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for mm, mass in enumerate(output[\"masses_test\"]) :\n",
    "    y_pred = data_even.loc[(data_even.target.values == 0) & (data_even[\"gen_mHH\"] == mass), \"NN_output\"].values\n",
    "    y_predS = data_even.loc[(data_even.target.values == 1) & (data_even[\"gen_mHH\"] == mass), \"NN_output\"].values\n",
    "    y_pred_train = data_odd.loc[(data_odd.target.values == 0) & (data_odd[\"gen_mHH\"] == mass), \"NN_output\"].values\n",
    "    y_predS_train = data_odd.loc[(data_odd.target.values == 1) & (data_odd[\"gen_mHH\"] == mass), \"NN_output\"].values\n",
    "    dict_plot = [\n",
    "       [y_pred, \"-\", colorhot[mm],  str(mass)+\" GeV test BKG\"],\n",
    "       [y_predS, \"-\", colorcold[mm], str(mass)+\" GeV test signal\"],\n",
    "       [y_pred_train, \"--\", colorhot[mm], str(mass)+\" GeV train BKG\" ],\n",
    "       [y_predS_train, \"--\", colorcold[mm],      str(mass)+\" GeV train signal\"]\n",
    "    ]\n",
    "    for item in dict_plot :\n",
    "        values1, bins, _ = ax.hist(\n",
    "            item[0],\n",
    "            ls=item[1], color = item[2],\n",
    "            label=item[3],\n",
    "            range=(0,1),\n",
    "            **hist_params\n",
    "            )\n",
    "        normed = sum(y_pred)\n",
    "        mid = 0.5*(bins[1:] + bins[:-1])\n",
    "        err=np.sqrt(values1*normed)/normed # denominator is because plot is normalized\n",
    "        plt.errorbar(mid, values1, yerr=err, fmt='none', color= item[2], ecolor= item[2], edgecolor=item[2], lw=2)\n",
    "#plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "ax.legend(loc='upper center', title=\"by mass \", fontsize = 'small')\n",
    "#nameout = channel+'/'+bdtType+'_'+trainvar+'_'+str(len(trainVars(False)))+'_'+hyppar+'_mass_'+ str(mass)+'_XGBclassifier.pdf'\n",
    "\n",
    "filename3=\"{}/NN_Output_by_mass_{}.pdf\".format(channel, hyppar) ## For gen_mHH as input Var.\n",
    "#filename3=\"{}/NN_Output_by_mass_{}.pdf\".format(channel, hyppar2) ## w/o gen_mHH as input Var.\n",
    "plt.savefig(filename3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# by mass ROC\n",
    "styleline = ['-', '--', '-.', ':']\n",
    "colors_mass = ['m', 'b', 'k', 'r', 'g',  'y', 'c', ]\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sl = 0\n",
    "\n",
    "\n",
    "for mm, mass in enumerate(output[\"masses_test\"]) :\n",
    "    for dd, data_do in  enumerate(order_train) :\n",
    "        if dd == 0 : val_data = 1\n",
    "        else : val_data = 0\n",
    "        fpr, tpr, thresholds = roc_curve(\n",
    "            data_do.loc[(data_do[\"gen_mHH\"] == mass), \"target\"].astype(np.bool),\n",
    "            data_do.loc[(data_do[\"gen_mHH\"] == mass), \"NN_output\"].values,\n",
    "            sample_weight=(data_do.loc[(data_do[\"gen_mHH\"].astype(np.int) == int(mass)), \"weight_cx\"].astype(np.float64))\n",
    "        )\n",
    "        train_auc = auc(fpr, tpr, reorder = True)\n",
    "        print(\"train set auc \" + str(train_auc) + \" (mass = \" + str(mass) + \")\")\n",
    "        fprt, tprt, thresholds = roc_curve(\n",
    "            order_train[val_data].loc[(order_train[val_data][\"gen_mHH\"].astype(np.int) == int(mass)), target].astype(np.bool), \n",
    "            order_train[val_data].loc[(order_train[val_data][\"gen_mHH\"] == mass), \"NN_output\"].values, #proba[:,1],\n",
    "            sample_weight=(order_train[val_data].loc[(order_train[val_data][\"gen_mHH\"].astype(np.int) == int(mass)), \"weight_cx\"].astype(np.float64))\n",
    "        )\n",
    "        test_auct = auc(fprt, tprt, reorder = True)\n",
    "        print(\"test set auc \" + str(test_auct) + \" (mass = \" + str(mass) + \")\")\n",
    "        ax.plot(\n",
    "            fpr, tpr,\n",
    "            lw = 2, linestyle = styleline[dd + dd*1], color = colors_mass[mm],\n",
    "            label = order_train_name[dd] + ' train (area = %0.3f)'%(train_auc) + \" (mass = \" + str(mass) + \")\"\n",
    "            )\n",
    "        sl += 1\n",
    "        ax.plot(\n",
    "            fprt, tprt,\n",
    "            lw = 2, linestyle = styleline[dd + 1 + + dd*1], color = colors_mass[mm],\n",
    "            label = order_train_name[dd] + ' test (area = %0.3f)'%(test_auct) + \" (mass = \" + str(mass) + \")\"\n",
    "            )\n",
    "        sl += 1\n",
    "ax.set_ylim([0.0,1.0])\n",
    "ax.set_xlim([0.0,1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.legend(loc=\"lower right\", fontsize = 'small')\n",
    "ax.grid()\n",
    "\n",
    "filename4=\"{}/ROC_by_mass_{}.pdf\".format(channel, hyppar) ## For gen_mHH as input Var.\n",
    "#filename4=\"{}/ROC_by_mass_{}.pdf\".format(channel, hyppar2) ## w/o gen_mHH as input Var.\n",
    "plt.savefig(filename4);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "features = trainvar # = BDTvariables\n",
    "features2 = BDTvariables_wo_gen_mHH\n",
    "\n",
    "#### ----- Interpolation check log files ----####                                                                                                                                                                                                                       \n",
    "styleline = ['-', '--', '-.', ':', 'solid']\n",
    "colors_mass = ['m', 'b', 'k', 'r', 'g',  'y', 'c', ]\n",
    "## ---- ROC CURVES ------###\n",
    "#fig1, ax1 = plt2.subplots(figsize=(6, 6))\n",
    "#fig2, ax2 = plt2.subplots(figsize=(6, 6))\n",
    "#fig3, ax3 = plt2.subplots(figsize=(6, 6))\n",
    "#sl = 0\n",
    "#s2 = 0\n",
    "#s3 = 0\n",
    "\n",
    "hist_params = {'normed': True, 'bins': 8 , 'histtype':'step', \"lw\": 2}\n",
    "plt.clf()\n",
    "colorcold = ['g', 'r', 'y', 'black', 'gray']\n",
    "colorhot = ['b', 'magenta', 'orange', 'cyan', 'brown']\n",
    "## ---- NN OUTPUT ---- ###\n",
    "fig1a, ax1a = plt.subplots(figsize=(6, 6))\n",
    "fig1b, ax1b = plt.subplots(figsize=(6, 6))\n",
    "fig1c, ax1c = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "for mm, mass in enumerate(test_masses): ## Loop over the test masses   \n",
    "#for mm, mass in enumerate([300]): ## Loop over 300 GeV test mass only      \n",
    "    print(\"mass\", mass)\n",
    "    MASS = int(mass)\n",
    "    print(\"MASS\", MASS)\n",
    "    MASS_STR = \"{}\".format(MASS)\n",
    "    print(\"MASS_STR\", MASS_STR)\n",
    "    \n",
    "    ## For writing the interpolation check roc curves ##\n",
    "    log_file2_name = \"{}/{}_{}.log\".format(channel,channel,MASS_STR)\n",
    "    file2_ = open(log_file2_name, 'w+')\n",
    "\n",
    "    for dd, data_do in  enumerate(order_train):   ## Loop over the odd and even dataset halves                                                                                                                                                                          \n",
    "        if dd == 0 : val_data = 1\n",
    "        else : val_data = 0\n",
    "        \n",
    "        if(Bkg_mass_rand == \"default\"):\n",
    "            print(\"Using the new logic\")\n",
    "            traindataset1 = data_do.loc[~((data_do[\"gen_mHH\"]==mass) & (data_do['target']==1))]  ## Training for all masses except the one under study only for signal process                                                                                            \n",
    "            #valdataset1   = order_train[val_data].loc[~((order_train[val_data][\"gen_mHH\"]==mass) & (order_train[val_data][target]==1))]  ## Testing for all masses except the one under study for signal process                                                       \n",
    "            valdataset1 = order_train[val_data].loc[~((order_train[val_data][\"gen_mHH\"]!=mass) & (order_train[val_data]['target']==1))] ## Testing on only the mass under study for signal                                                                                \n",
    "        else:\n",
    "            print(\"Using the old logic\")\n",
    "            traindataset1 = data_do.loc[~(data_do[\"gen_mHH\"]==mass)]  ## Training for all masses except the one under study                                                                                                                                             \n",
    "            #valdataset1 = order_train[val_data].loc[~(order_train[val_data][\"gen_mHH\"]==mass)]  ## Testing for all masses except the one under study                                                                                                                   \n",
    "            valdataset1 = order_train[val_data].loc[(order_train[val_data][\"gen_mHH\"]==mass)] ## Testing on only the mass under study\n",
    "        \n",
    "        \n",
    "        if(mass == 300):\n",
    "            if(TrainMode == 0):\n",
    "                masses1 = [250,260,270,280,350,400,450,500,550,600,650,700,750,800,850,900,1000] ## All masses except 300                                                                                                                                               \n",
    "                masses_test1 = [250,1000]\n",
    "            elif(TrainMode == 1):\n",
    "                masses1 = [250,260,270,280,350,400] ## Low mass only training (except 300)                                                                                                                                                                              \n",
    "                masses_test1 = [250]\n",
    "            masses2 = [300]\n",
    "            masses_test2 = [300]\n",
    "        elif(mass == 500):\n",
    "            if(TrainMode == 0):\n",
    "                masses1 = [250,260,270,280,300,350,400,450,550,600,650,700,750,800,850,900,1000] ## All masses except 500                                                                                                                                               \n",
    "                masses_test1 = [250,1000]\n",
    "            elif(TrainMode == 2):\n",
    "                masses1 = [450,550,600,650,700,750,800,850,900,1000] ## High mass only training (except 500)                                                                                                                                                            \n",
    "                masses_test1 = [1000]\n",
    "            masses2 = [500]\n",
    "            masses_test2 = [500]\n",
    "        elif(mass == 800):\n",
    "            if(TrainMode == 0):\n",
    "                masses1 = [250,260,270,280,300,350,400,450,500,550,600,650,700,750,850,900,1000] ## All masses except 800                                                                                                                                               \n",
    "                masses_test1 = [250,1000]\n",
    "            elif(TrainMode == 2):\n",
    "                masses1 = [450,500,550,600,650,700,750,850,900,1000] ## High mass only training (except 800)                                                                                                                                                            \n",
    "                masses_test1 = [1000]\n",
    "            masses2 = [800]\n",
    "            masses_test2 = [800]\n",
    "           \n",
    "        \n",
    "        ################# WITH gen_mHH #####################                                                                                                                                                                                                            \n",
    "        k_model_binary2  = KerasClassifier(\n",
    "                       build_fn=nn_model_binary, \n",
    "                       epochs=EPOCHS, # 10\n",
    "                       batch_size=BATCH_SIZE, # 64\n",
    "                       verbose=2\n",
    "                       )\n",
    "        \n",
    "        history2 = k_model_binary2.fit(\n",
    "               traindataset1[features].values, \n",
    "               traindataset1['target'].values,\n",
    "               sample_weight=traindataset1[\"weight_train\"].values,\n",
    "               validation_data=(\n",
    "                   valdataset1[features].values, \n",
    "                   valdataset1['target'].values, \n",
    "                   valdataset1[\"weight_train\"].values\n",
    "               )\n",
    "        )\n",
    "\n",
    "        traindataset1[\"NN_output2\"] = 1.0\n",
    "        valdataset1[\"NN_output2\"]   = 1.0\n",
    "        \n",
    "        ## --- ROC curve ----##                                                                                                                                                                                                                                         \n",
    "        #proba = cls2.predict_proba(valdataset1[trainVars(False, options.variables, options.bdtType)].values )\n",
    "        valdataset1[\"NN_output2\"] = k_model_binary2.predict_proba(valdataset1[features].values, verbose=1)[:, 1]\n",
    "        fprt, tprt, thresholds = roc_curve(valdataset1['target'].astype(np.bool), valdataset1[\"NN_output2\"].values, sample_weight=(valdataset1[\"weight_cx\"].astype(np.float64)) )\n",
    "        test_auct = auc(fprt, tprt, reorder = True)\n",
    "\n",
    "        #proba = cls2.predict_proba(traindataset1[trainVars(False, options.variables, options.bdtType)].values )\n",
    "        traindataset1[\"NN_output2\"] = k_model_binary2.predict_proba(traindataset1[features].values, verbose=1)[:, 1]\n",
    "        fpr, tpr, thresholds = roc_curve(traindataset1['target'].astype(np.bool), traindataset1[\"NN_output2\"].values, sample_weight=(traindataset1[\"weight_cx\"].astype(np.float64)) )\n",
    "        train_auc = auc(fpr, tpr, reorder = True)\n",
    "\n",
    "        ## ---- BDT Output Distributions ----- ###                                                                                                                                                                                                                      \n",
    "        y_pred = k_model_binary2.predict_proba(valdataset1.ix[valdataset1.target.values == 0, BDTvariables].values)[:, 1]\n",
    "        y_predS = k_model_binary2.predict_proba(valdataset1.ix[valdataset1.target.values == 1, BDTvariables].values)[:, 1]\n",
    "        \n",
    "        y_pred_train = k_model_binary2.predict_proba(traindataset1.ix[traindataset1.target.values == 0, BDTvariables].values)[:, 1]\n",
    "        y_predS_train = k_model_binary2.predict_proba(traindataset1.ix[traindataset1.target.values == 1, BDTvariables].values)[:, 1]\n",
    "\n",
    "        file2_.write('#------ Training for all masses except %0.1f GeV-------\\n' %mass)\n",
    "        file2_.write('#------ Testing only for mass %0.1f GeV (using other dataset half)--------\\n' %mass)\n",
    "        if(dd == 0): ## Train->odd; Test/val -> even                                                                                                                                                                                                                    \n",
    "            file2_.write('train_auc_ODD0_%s = %0.8f\\n' % (MASS_STR, train_auc))\n",
    "            file2_.write('test_auc_EVEN0_%s  = %0.8f\\n' % (MASS_STR, test_auct))\n",
    "            file2_.write('xtrain_ODD0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fpr.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('ytrain_ODD0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tpr.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('xval_EVEN0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fprt.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('yval_EVEN0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tprt.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_test_EVEN0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_test_EVEN0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_train_ODD0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred_train.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_train_ODD0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS_train.tolist()))\n",
    "            file2_.write('\\n')\n",
    "        else: ## Train->even; Test/val -> odd                                                                                                                                                                                                                           \n",
    "            file2_.write('train_auc_EVEN0_%s = %0.8f\\n' %  (MASS_STR, train_auc))\n",
    "            file2_.write('test_auc_ODD0_%s  = %0.8f\\n' %  (MASS_STR, test_auct))\n",
    "            file2_.write('xtrain_EVEN0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fpr.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('ytrain_EVEN0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tpr.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('xval_ODD0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fprt.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('yval_ODD0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tprt.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_test_ODD0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_test_ODD0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_train_EVEN0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred_train.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_train_EVEN0_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS_train.tolist()))\n",
    "            file2_.write('\\n')\n",
    "        file2_.write('##-------------------------------------------##\\n')\n",
    "        ################################################### \n",
    "        \n",
    "        ## ---- ROC curves ---###\n",
    "        #ax1.plot( \n",
    "        #    fpr, tpr,\n",
    "        #    lw = 2, linestyle = styleline[dd + dd*1], color = colors_mass[0],\n",
    "        #    label = order_train_name[dd] + ' train all except %s GeV w gen_mHH (area = %0.3f)'%(str(mass), train_auc)\n",
    "        #    )\n",
    "        #sl += 1\n",
    "        #ax1.plot(\n",
    "        #    fprt, tprt,\n",
    "        #    lw = 2, linestyle = styleline[dd + 1 + + dd*1], color = colors_mass[0],\n",
    "        #    label = order_train_name[dd] + ' test only %s GeV w gen_mHH (area = %0.3f)'%(str(mass), test_auct)\n",
    "        #    )\n",
    "        #sl += 1\n",
    "        \n",
    "        ## Plot NN Output Histograms\n",
    "        if dd == 0 : # Odd train, Even test\n",
    "            dict_plot = [ ## Output Histogtams\n",
    "                   [y_pred, \"-\", colorhot[mm],  str(mass)+\" GeV test BKG (Even)\"],\n",
    "                   [y_predS, \"-\", colorcold[mm], str(mass)+\" GeV test signal (Even)\"],\n",
    "                   [y_pred_train, \"--\", colorhot[mm], str(mass)+\" GeV train BKG (Odd)\" ],\n",
    "                   [y_predS_train, \"--\", colorcold[mm],      str(mass)+\" GeV train signal (Odd)\"]\n",
    "                ]\n",
    "        else: # Even train, Odd test\n",
    "            dict_plot = [ ## Output Histogtams\n",
    "                   [y_pred, \"-\", colorhot[mm+1],  str(mass)+\" GeV test BKG (Odd)\"],\n",
    "                   [y_predS, \"-\", colorcold[mm+1], str(mass)+\" GeV test signal (Odd)\"],\n",
    "                   [y_pred_train, \"--\", colorhot[mm+1], str(mass)+\" GeV train BKG (Even)\" ],\n",
    "                   [y_predS_train, \"--\", colorcold[mm+1],      str(mass)+\" GeV train signal (Even)\"]\n",
    "                ]\n",
    "            \n",
    "        for item in dict_plot :\n",
    "            values1, bins, _ = ax1a.hist(\n",
    "                item[0],\n",
    "                ls=item[1], color = item[2],\n",
    "                label=item[3],\n",
    "                range=(0,1),\n",
    "                **hist_params\n",
    "                )\n",
    "            normed = sum(y_pred)\n",
    "            mid = 0.5*(bins[1:] + bins[:-1])\n",
    "            err=np.sqrt(values1*normed)/normed # denominator is because plot is normalized\n",
    "            plt.errorbar(mid, values1, yerr=err, fmt='none', color= item[2], ecolor= item[2], edgecolor=item[2], lw=2)\n",
    "        del dict_plot[:] ## Clearing the list    \n",
    "        \n",
    "        ################# W/O gen_mHH #####################                                                                                                                                                                                                             \n",
    "        k_model_binary2a = KerasClassifier(\n",
    "                       build_fn=nn_model_binary_wo_gen_mHH, \n",
    "                       epochs=EPOCHS2, # 10\n",
    "                       batch_size=BATCH_SIZE2, # 64\n",
    "                       verbose=2\n",
    "                       )\n",
    "\n",
    "        history2a = k_model_binary2a.fit(\n",
    "               traindataset1[BDTvariables_wo_gen_mHH].values, \n",
    "               traindataset1['target'].values,\n",
    "               sample_weight=traindataset1[\"weight_train\"].values,\n",
    "               validation_data=(\n",
    "                   valdataset1[BDTvariables_wo_gen_mHH].values, \n",
    "                   valdataset1['target'].values, \n",
    "                   valdataset1[\"weight_train\"].values\n",
    "               )\n",
    "        )\n",
    "\n",
    "        traindataset1[\"NN_output2a\"] = 1.0\n",
    "        valdataset1[\"NN_output2a\"]   = 1.0\n",
    "        \n",
    "        ## --- ROC curve ----##                                                                                                                                                                                                                                         \n",
    "        #proba_a = cls2a.predict_proba(valdataset1[BDTvariables_wo_gen_mHH].values )\n",
    "        valdataset1[\"NN_output2a\"] = k_model_binary2a.predict_proba(valdataset1[BDTvariables_wo_gen_mHH].values , verbose=1)[:, 1]\n",
    "        fprt_a, tprt_a, thresholds = roc_curve(valdataset1['target'].astype(np.bool), valdataset1[\"NN_output2a\"].values, sample_weight=(valdataset1[\"weight_cx\"].astype(np.float64))  )\n",
    "        test_auct_a = auc(fprt_a, tprt_a, reorder = True)\n",
    "\n",
    "        #proba_a = cls2a.predict_proba(traindataset1[BDTvariables_wo_gen_mHH].values )\n",
    "        traindataset1[\"NN_output2a\"] = k_model_binary2a.predict_proba(traindataset1[BDTvariables_wo_gen_mHH].values , verbose=1)[:, 1]\n",
    "        fpr_a, tpr_a, thresholds = roc_curve(traindataset1['target'].astype(np.bool), traindataset1[\"NN_output2a\"].values, sample_weight=(traindataset1[\"weight_cx\"].astype(np.float64)) )\n",
    "        train_auc_a = auc(fpr_a, tpr_a, reorder = True)\n",
    "\n",
    "        ## ---- BDT Output Distributions ----- ###                                                                                                                                                                                                                      \n",
    "        y_pred_a = k_model_binary2a.predict_proba(valdataset1.ix[valdataset1.target.values == 0, BDTvariables_wo_gen_mHH].values)[:, 1]\n",
    "        y_predS_a = k_model_binary2a.predict_proba(valdataset1.ix[valdataset1.target.values == 1, BDTvariables_wo_gen_mHH].values)[:, 1]\n",
    "\n",
    "        y_pred_train_a = k_model_binary2a.predict_proba(traindataset1.ix[traindataset1.target.values == 0, BDTvariables_wo_gen_mHH].values)[:, 1]\n",
    "        y_predS_train_a = k_model_binary2a.predict_proba(traindataset1.ix[traindataset1.target.values == 1, BDTvariables_wo_gen_mHH].values)[:, 1]\n",
    "        \n",
    "        file2_.write('#------ Training for all masses except %0.1f GeV (w/o gen_mHH)-------\\n' %mass)\n",
    "        file2_.write('#------ Testing only for mass %0.1f GeV using other dataset half (w/o gen_mHH)--------\\n' %mass)\n",
    "        if(dd == 0): ## Train->odd; Test/val -> even                                                                                                                                                                                                                    \n",
    "            file2_.write('train_auc_ODD0a_%s = %0.8f\\n' % (MASS_STR, train_auc_a))\n",
    "            file2_.write('test_auc_EVEN0a_%s  = %0.8f\\n' % (MASS_STR, test_auct_a))\n",
    "            file2_.write('xtrain_ODD0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fpr_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('ytrain_ODD0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tpr_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('xval_EVEN0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fprt_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('yval_EVEN0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tprt_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_test_EVEN0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_test_EVEN0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_train_ODD0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred_train_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_train_ODD0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS_train_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "        else: ## Train->even; Test/val -> odd                                                                                                                                                                                                                           \n",
    "            file2_.write('train_auc_EVEN0a_%s = %0.8f\\n' %  (MASS_STR, train_auc_a))\n",
    "            file2_.write('test_auc_ODD0a_%s  = %0.8f\\n' %  (MASS_STR, test_auct_a))\n",
    "            file2_.write('xtrain_EVEN0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fpr_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('ytrain_EVEN0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tpr_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('xval_ODD0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fprt_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('yval_ODD0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tprt_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_test_ODD0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_test_ODD0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_train_EVEN0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred_train_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_train_EVEN0a_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS_train_a.tolist()))\n",
    "            file2_.write('\\n')\n",
    "        file2_.write('##-------------------------------------------##\\n')\n",
    "        ################################################### \n",
    "        \n",
    "        ## --- ROC Curves --- ##\n",
    "        #ax2.plot(\n",
    "        #    fpr_a, tpr_a,\n",
    "        #    lw = 2, linestyle = styleline[dd + dd*1], color = colors_mass[1],\n",
    "        #    label = order_train_name[dd] + ' train all except %s GeV w/o gen_mHH (area = %0.3f)'%(str(mass), train_auc_a)\n",
    "        #    )\n",
    "        #s2 += 1\n",
    "        #ax2.plot(\n",
    "        #    fprt_a, tprt_a,\n",
    "        #    lw = 2, linestyle = styleline[dd + 1 + + dd*1], color = colors_mass[1],\n",
    "        #    label = order_train_name[dd] + ' test only %s GeV w/o gen_mHH (area = %0.3f)'%(str(mass), test_auct_a)\n",
    "        #    )\n",
    "        #s2 += 1\n",
    "        \n",
    "        ## Plot NN Output Histograms\n",
    "        if dd == 0 : # Odd train, Even test\n",
    "            dict_plot2 = [ ## Output Histogtams\n",
    "                   [y_pred_a, \"-\", colorhot[mm],  str(mass)+\" GeV test BKG (Even)\"],\n",
    "                   [y_predS_a, \"-\", colorcold[mm], str(mass)+\" GeV test signal (Even)\"],\n",
    "                   [y_pred_train_a, \"--\", colorhot[mm], str(mass)+\" GeV train BKG (Odd)\" ],\n",
    "                   [y_predS_train_a, \"--\", colorcold[mm],      str(mass)+\" GeV train signal (Odd)\"]\n",
    "                ]\n",
    "        else: # Even train, Odd test\n",
    "            dict_plot2 = [ ## Output Histogtams\n",
    "                   [y_pred_a, \"-\", colorhot[mm+1],  str(mass)+\" GeV test BKG (Odd)\"],\n",
    "                   [y_predS_a, \"-\", colorcold[mm+1], str(mass)+\" GeV test signal (Odd)\"],\n",
    "                   [y_pred_train_a, \"--\", colorhot[mm+1], str(mass)+\" GeV train BKG (Even)\" ],\n",
    "                   [y_predS_train_a, \"--\", colorcold[mm+1],      str(mass)+\" GeV train signal (Even)\"]\n",
    "                ]\n",
    "            \n",
    "        for item in dict_plot2 :\n",
    "            values1, bins, _ = ax1b.hist(\n",
    "                item[0],\n",
    "                ls=item[1], color = item[2],\n",
    "                label=item[3],\n",
    "                range=(0,1),\n",
    "                **hist_params\n",
    "                )\n",
    "            normed = sum(y_pred_a)\n",
    "            mid = 0.5*(bins[1:] + bins[:-1])\n",
    "            err=np.sqrt(values1*normed)/normed # denominator is because plot is normalized\n",
    "            plt.errorbar(mid, values1, yerr=err, fmt='none', color= item[2], ecolor= item[2], edgecolor=item[2], lw=2)\n",
    "        del dict_plot2[:] ## Clearing the list \n",
    "            \n",
    "        ## --- Single Mass training ----##                                                                                                                                                                                                                                         \n",
    "        if(Bkg_mass_rand == \"default\"):\n",
    "            print(\"Using the new logic\")\n",
    "            #traindataset2 = data_do.loc[(data_do[\"gen_mHH\"]==mass)]  ## Training for only the mass point under study                                                                                                                                                   \n",
    "            traindataset2 = data_do.loc[ ~((data_do[\"gen_mHH\"]!=mass) & (data_do['target']==1)) ]  ## Training for only the mass point under study (for the signal process)                                                                                               \n",
    "            valdataset2 = order_train[val_data].loc[ ~((order_train[val_data][\"gen_mHH\"]!=mass) & (order_train[val_data]['target']==1)) ]  ## Testing for only the mass point under study (for the signal process)                                                        \n",
    "        else:\n",
    "            print(\"Using the old logic\")\n",
    "            traindataset2 = data_do.loc[(data_do[\"gen_mHH\"]==mass)]  ## Training for only the mass point under study                                                                                                                                                    \n",
    "            valdataset2 = order_train[val_data].loc[(order_train[val_data][\"gen_mHH\"]==mass)]  ## Testing for only the mass point under study                                                                                                                           \n",
    "\n",
    "        #traindataset2 = data_do.loc[(data_do[\"gen_mHH\"]==mass)]  ## Training for only the mass point under study                                                                                                                                                       \n",
    "        #valdataset2 = order_train[val_data].loc[(order_train[val_data][\"gen_mHH\"]==mass)]  ## Testing for only the mass point under study                                                                                                                              \n",
    "\n",
    "       \n",
    "        k_model_binary3 = KerasClassifier(\n",
    "                       build_fn=nn_model_binary_wo_gen_mHH, \n",
    "                       epochs=EPOCHS2, # 10\n",
    "                       batch_size=BATCH_SIZE2, # 64\n",
    "                       verbose=2\n",
    "                       #build_fn=nn_model_binary, \n",
    "                       #epochs=EPOCHS, # 10\n",
    "                       #batch_size=BATCH_SIZE, # 64\n",
    "                       #verbose=2\n",
    "                       )\n",
    "        \n",
    "        history3 = k_model_binary3.fit(\n",
    "               traindataset2[BDTvariables_wo_gen_mHH].values, ## Since we are doing single mass train no need for gen_mHH\n",
    "               #traindataset2[BDTvariables].values,\n",
    "               traindataset2['target'].values,\n",
    "               sample_weight=traindataset2[\"weight_train\"].values,\n",
    "               validation_data=(\n",
    "                   valdataset2[BDTvariables_wo_gen_mHH].values,\n",
    "                   #valdataset2[BDTvariables].values,\n",
    "                   valdataset2['target'].values, \n",
    "                   valdataset2[\"weight_train\"].values\n",
    "               )\n",
    "        )\n",
    "        \n",
    "        traindataset2[\"NN_output3\"] = 1.0\n",
    "        valdataset2[\"NN_output3\"]   = 1.0\n",
    "        \n",
    "        valdataset2[\"NN_output3\"] = k_model_binary3.predict_proba(valdataset2[BDTvariables_wo_gen_mHH].values , verbose=1)[:, 1] ## Since we are doing single mass train no need for gen_mHH\n",
    "        #valdataset2[\"NN_output3\"] = k_model_binary3.predict_proba(valdataset2[BDTvariables].values )\n",
    "        fprt3, tprt3, thresholds3 = roc_curve(valdataset2['target'].astype(np.bool), valdataset2[\"NN_output3\"].values, sample_weight=(valdataset2[\"weight_cx\"].astype(np.float64))  )\n",
    "        print(\"fprt3\", fprt3)\n",
    "        print(\"tprt3\", tprt3)\n",
    "        test_auct = auc(fprt3, tprt3, reorder = True)\n",
    "\n",
    "        traindataset2[\"NN_output3\"] = k_model_binary3.predict_proba(traindataset2[BDTvariables_wo_gen_mHH].values , verbose=1)[:, 1] ## Since we are doing single mass train no need for gen_mHH                                                                                                                          \n",
    "        #traindataset2[\"NN_output3\"] = k_model_binary3.predict_proba(traindataset2[BDTvariables].values )\n",
    "        fpr3, tpr3, thresholds3 = roc_curve(traindataset2['target'].astype(np.bool), traindataset2[\"NN_output3\"].values, sample_weight=(traindataset2[\"weight_cx\"].astype(np.float64)) )\n",
    "        train_auc = auc(fpr3, tpr3, reorder = True)\n",
    "\n",
    "        ## ---- BDT Output Distributions ----- ###                                                                                                                                                                                                                      \n",
    "        y_pred_3 = k_model_binary3.predict_proba(valdataset2.ix[valdataset2.target.values == 0, BDTvariables_wo_gen_mHH].values)[:, 1]   ## Since we are doing single mass train no need for gen_mHH                                                                                 \n",
    "        y_predS_3 = k_model_binary3.predict_proba(valdataset2.ix[valdataset2.target.values == 1, BDTvariables_wo_gen_mHH].values)[:, 1]  ## Since we are doing single mass train no need for gen_mHH                                                                                 \n",
    "\n",
    "        y_pred_train_3 = k_model_binary3.predict_proba(traindataset2.ix[traindataset2.target.values == 0, BDTvariables_wo_gen_mHH].values)[:, 1]  ## Since we are doing single mass train no need for gen_mHH                                                                        \n",
    "        y_predS_train_3 = k_model_binary3.predict_proba(traindataset2.ix[traindataset2.target.values == 1, BDTvariables_wo_gen_mHH].values)[:, 1] ## Since we are doing single mass train no need for gen_mHH \n",
    "  \n",
    "        #y_pred_3 = k_model_binary3.predict_proba(valdataset2.ix[valdataset2.target.values == 0, BDTvariables].values)[:, 1]\n",
    "        #y_predS_3 = k_model_binary3.predict_proba(valdataset2.ix[valdataset2.target.values == 1, BDTvariables].values)[:, 1]\n",
    "    \n",
    "        #y_pred_train_3 = k_model_binary3.predict_proba(traindataset2.ix[traindataset2.target.values == 0, BDTvariables].values)[:, 1]\n",
    "        #y_predS_train_3 = k_model_binary3.predict_proba(traindataset2.ix[traindataset2.target.values == 1, BDTvariables].values)[:, 1] \n",
    "    \n",
    "        file2_.write('#------ Training for only mass %0.1f GeV-------\\n' %mass)\n",
    "        file2_.write('#------ Testing for only mass %0.1f GeV (using other data half)--------\\n' %mass)\n",
    "        if(dd == 0): ## Train->odd; Test/val -> even                                                                                                                                                                                                                    \n",
    "            file2_.write('train_auc_ODD1_%s = %0.8f\\n' % (MASS_STR, train_auc))\n",
    "            file2_.write('test_auc_EVEN1_%s  = %0.8f\\n' % (MASS_STR, test_auct))\n",
    "            file2_.write('xtrain_ODD1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fpr3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('ytrain_ODD1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tpr3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('xval_EVEN1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fprt3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('yval_EVEN1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tprt3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_test_EVEN1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred_3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_test_EVEN1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS_3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_train_ODD1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred_train_3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_train_ODD1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS_train_3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "        else: ## Train->even; Test/val -> odd                                                                                                                                                                                                                           \n",
    "            file2_.write('train_auc_EVEN1_%s = %0.8f\\n' %  (MASS_STR, train_auc))\n",
    "            file2_.write('test_auc_ODD1_%s  = %0.8f\\n' % (MASS_STR, test_auct))\n",
    "            file2_.write('xtrain_EVEN1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fpr3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('ytrain_EVEN1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tpr3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('xval_ODD1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(fprt3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('yval_ODD1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(tprt3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_test_ODD1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred_3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_test_ODD1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS_3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_pred_train_EVEN1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_pred_train_3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "            file2_.write('y_predS_train_EVEN1_%s = ' % (MASS_STR))\n",
    "            file2_.write(str(y_predS_train_3.tolist()))\n",
    "            file2_.write('\\n')\n",
    "        file2_.write('##-------------------------------------------##\\n')\n",
    "        \n",
    "        ## ---- ROC Curves ---- ##\n",
    "        #ax3.plot(\n",
    "        #    fpr3, tpr3,\n",
    "        #    lw = 2, linestyle = styleline[dd + dd*1], color = colors_mass[2],\n",
    "        #    label = order_train_name[dd] + ' Single mass train %s GeV (area = %0.3f)'%(str(mass), train_auc)\n",
    "        #    )\n",
    "        #s3 += 1\n",
    "        #ax3.plot(\n",
    "        #    fprt3, tprt3,\n",
    "        #    lw = 2, linestyle = styleline[dd + 1 + + dd*1], color = colors_mass[2],\n",
    "        #    label = order_train_name[dd] + ' Single mass test %s GeV (area = %0.3f)'%(str(mass), test_auct)\n",
    "        #    )\n",
    "        #s3 += 1\n",
    "        \n",
    "        \n",
    "        ## Plot NN Output Histograms\n",
    "        if dd == 0 : # Odd train, Even test\n",
    "            dict_plot3 = [ ## Output Histogtams\n",
    "                   [y_pred_3, \"-\", colorhot[mm],  str(mass)+\" GeV test BKG (Even)\"],\n",
    "                   [y_predS_3, \"-\", colorcold[mm], str(mass)+\" GeV test signal (Even)\"],\n",
    "                   [y_pred_train_3, \"--\", colorhot[mm], str(mass)+\" GeV train BKG (Odd)\" ],\n",
    "                   [y_predS_train_3, \"--\", colorcold[mm],      str(mass)+\" GeV train signal (Odd)\"]\n",
    "                ]\n",
    "        else: # Even train, Odd test\n",
    "            dict_plot3 = [ ## Output Histogtams\n",
    "                   [y_pred_3, \"-\", colorhot[mm+1],  str(mass)+\" GeV test BKG (Odd)\"],\n",
    "                   [y_predS_3, \"-\", colorcold[mm+1], str(mass)+\" GeV test signal (Odd)\"],\n",
    "                   [y_pred_train_3, \"--\", colorhot[mm+1], str(mass)+\" GeV train BKG (Even)\" ],\n",
    "                   [y_predS_train_3, \"--\", colorcold[mm+1], str(mass)+\" GeV train signal (Even)\"]\n",
    "                ]\n",
    "            \n",
    "        for item in dict_plot3 :\n",
    "            values1, bins, _ = ax1c.hist(\n",
    "                item[0],\n",
    "                ls=item[1], color = item[2],\n",
    "                label=item[3],\n",
    "                range=(0,1),\n",
    "                **hist_params\n",
    "                )\n",
    "            normed = sum(y_pred_3)\n",
    "            mid = 0.5*(bins[1:] + bins[:-1])\n",
    "            err=np.sqrt(values1*normed)/normed # denominator is because plot is normalized\n",
    "            plt.errorbar(mid, values1, yerr=err, fmt='none', color= item[2], ecolor= item[2], edgecolor=item[2], lw=2)\n",
    "        del dict_plot3[:] ## Clearing the list\n",
    "        \n",
    "    file2_.close()\n",
    "    \n",
    "    #plt.yscale('log')\n",
    "    ax1a.legend(loc='upper center', title=\"by mass \", fontsize = 'small')\n",
    "    ax1b.legend(loc='upper center', title=\"by mass \", fontsize = 'small')\n",
    "    ax1c.legend(loc='upper center', title=\"by mass \", fontsize = 'small')\n",
    "    if dd == 0: # Odd train, Even test\n",
    "        filename3a=\"{}/NN_Output_Odd_TrainOnAllExcept_{}_Even_TestOn_{}_w_gen_mHH_{}.pdf\".format(channel, str(mass), str(mass), hyppar) ## For gen_mHH as input Var.\n",
    "        fig1a.savefig(filename3a);\n",
    "        filename3b=\"{}/NN_Output_Odd_TrainOnAllExcept_{}_Even_TestOn_{}_wo_gen_mHH_{}.pdf\".format(channel, str(mass), str(mass), hyppar) ## For gen_mHH as input Var.\n",
    "        fig1b.savefig(filename3b);\n",
    "        filename3c=\"{}/NN_Output_Odd_TrainOnAllExcept_{}_Even_TestOn_{}_SingleMass_{}.pdf\".format(channel, str(mass), str(mass), hyppar) ## For gen_mHH as input Var.\n",
    "        fig1c.savefig(filename3c);\n",
    "    else: # Even train, Odd test \n",
    "        filename3a=\"{}/NN_Output_Even_TrainOnAllExcept_{}_Odd_TestOn_{}_w_gen_mHH_{}.pdf\".format(channel, str(mass), str(mass), hyppar) ## For gen_mHH as input Var.\n",
    "        fig1a.savefig(filename3a);\n",
    "        filename3b=\"{}/NN_Output_Even_TrainOnAllExcept_{}_Odd_TestOn_{}_wo_gen_mHH_{}.pdf\".format(channel, str(mass), str(mass), hyppar) ## For gen_mHH as input Var.\n",
    "        fig1b.savefig(filename3b);\n",
    "        filename3c=\"{}/NN_Output_Even_TrainOnAllExcept_{}_Odd_TestOn_{}_SingleMass_{}.pdf\".format(channel, str(mass), str(mass), hyppar) ## For gen_mHH as input Var.\n",
    "        fig1c.savefig(filename3c);\n",
    "       \n",
    "'''       \n",
    "ax1.set_ylim([0.0,1.0])\n",
    "ax1.set_xlim([0.0,1.0])\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.legend(loc=\"lower right\", fontsize = 'small')\n",
    "ax1.grid()\n",
    "filename4a=\"{}/ROC_Interpol_BDT_w_genmHH_{}.pdf\".format(channel, hyppar) ## For gen_mHH as input Var.\n",
    "#filename4=\"{}/ROC_by_mass_{}.pdf\".format(channel, hyppar2) ## w/o gen_mHH as input Var.\n",
    "plt2.savefig(filename4a);\n",
    "\n",
    "ax2.set_ylim([0.0,1.0])\n",
    "ax2.set_xlim([0.0,1.0])\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate')\n",
    "ax2.legend(loc=\"upper left\", fontsize = 'small')\n",
    "ax2.grid()\n",
    "filename4b=\"{}/ROC_Interpol_BDT_wo_genmHH_{}.pdf\".format(channel, hyppar) ## For gen_mHH as input Var.\n",
    "plt2.savefig(filename4b);\n",
    "\n",
    "ax3.set_ylim([0.0,1.0])\n",
    "ax3.set_xlim([0.0,1.0])\n",
    "ax3.set_xlabel('False Positive Rate')\n",
    "ax3.set_ylabel('True Positive Rate')\n",
    "ax3.legend(loc=\"upper left\", fontsize = 'small')\n",
    "ax3.grid()\n",
    "filename4c=\"{}/ROC_Single_Mass_wo_genmHH_{}.pdf\".format(channel, hyppar) ## For gen_mHH as input Var.\n",
    "plt2.savefig(filename4c);\n",
    "### ---------------------------------------- #### \n",
    "'''        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "output a training and export to .pb (to be used on cpp)\n",
    "\"\"\"\n",
    "print (\"Date: \", time.asctime( time.localtime(time.time()) ))\n",
    "nameout = \"model_erase\"\n",
    "\n",
    "out = k_model_binary.model.save(\"test_\"+nameout+\"_\"+hyppar+\"_Odd.hdf5\")\n",
    "file = open(nameout+\"_variables.log\",\"w\")\n",
    "file.write(str(features)+\"\\n\")\n",
    "file.close()\n",
    "\n",
    "out = k_model_binary2.model.save(\"test_\"+nameout+\"_\"+hyppar+\"_Even.hdf5\")\n",
    "file = open(nameout+\"_variables.log\",\"w\")\n",
    "file.write(str(features)+\"\\n\")\n",
    "file.close()\n",
    "\n",
    "\n",
    "## This bellow does not work, easier to be done on the command line,\n",
    "## in any case the bellow is a template how to run it\n",
    "##!python ../test/convert_hdf5_2_pb.py --input \"test_\"+nameout+\".hdf5\" --output \"test_\"+nameout+\".pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If you want to load a model to reconpute anything or check loading just substitute k_model --> k_model_loaded\n",
    "It only loads hdf5 format\n",
    "\"\"\"\n",
    "from keras.models import load_model\n",
    "k_model_loaded = load_model(\"test_model_2lss_ttH_3cat_no4mom_noSemi_v6.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the next do correlation matrices with variables\n",
    "import seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for target in [0,1] :\n",
    "    corr_mat = data.loc[(data['target']==0), features].astype(float).corr() #\n",
    "    fig, ax = plt.subplots(figsize=(20, 12)) \n",
    "    seaborn.heatmap(corr_mat, square=True, ax=ax, vmin=-1., vmax=1.)\n",
    "    if(target == 0) : filename4=\"{}/Signal_Correl_{}.pdf\".format(channel, hyppar)\n",
    "    else: filename4=\"{}/Background_Correl_{}.pdf\".format(channel, hyppar)   \n",
    "    plt.savefig(filename4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
